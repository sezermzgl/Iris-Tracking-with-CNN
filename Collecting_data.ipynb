{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = 'data/images'\n",
    "number_images = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting image 5\n",
      "Collecting image 6\n",
      "Collecting image 7\n",
      "Collecting image 8\n",
      "Collecting image 9\n",
      "Collecting image 10\n",
      "Collecting image 11\n",
      "Collecting image 12\n",
      "Collecting image 13\n",
      "Collecting image 14\n",
      "Collecting image 15\n",
      "Collecting image 16\n",
      "Collecting image 17\n",
      "Collecting image 18\n",
      "Collecting image 19\n",
      "Collecting image 20\n",
      "Collecting image 21\n",
      "Collecting image 22\n",
      "Collecting image 23\n",
      "Collecting image 24\n",
      "Collecting image 25\n",
      "Collecting image 26\n",
      "Collecting image 27\n",
      "Collecting image 28\n",
      "Collecting image 29\n",
      "Collecting image 30\n",
      "Collecting image 31\n",
      "Collecting image 32\n",
      "Collecting image 33\n",
      "Collecting image 34\n",
      "Collecting image 35\n",
      "Collecting image 36\n",
      "Collecting image 37\n",
      "Collecting image 38\n",
      "Collecting image 39\n",
      "Collecting image 40\n",
      "Collecting image 41\n",
      "Collecting image 42\n",
      "Collecting image 43\n",
      "Collecting image 44\n",
      "Collecting image 45\n",
      "Collecting image 46\n",
      "Collecting image 47\n",
      "Collecting image 48\n",
      "Collecting image 49\n",
      "Collecting image 50\n",
      "Collecting image 51\n",
      "Collecting image 52\n",
      "Collecting image 53\n",
      "Collecting image 54\n",
      "Collecting image 55\n",
      "Collecting image 56\n",
      "Collecting image 57\n",
      "Collecting image 58\n",
      "Collecting image 59\n",
      "Collecting image 60\n",
      "Collecting image 61\n",
      "Collecting image 62\n",
      "Collecting image 63\n",
      "Collecting image 64\n",
      "Collecting image 65\n",
      "Collecting image 66\n",
      "Collecting image 67\n",
      "Collecting image 68\n",
      "Collecting image 69\n",
      "Collecting image 70\n",
      "Collecting image 71\n",
      "Collecting image 72\n",
      "Collecting image 73\n",
      "Collecting image 74\n",
      "Collecting image 75\n",
      "Collecting image 76\n",
      "Collecting image 77\n",
      "Collecting image 78\n",
      "Collecting image 79\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "for imgnum in range(number_images):\n",
    "    print('Collecting image {}'.format(imgnum))\n",
    "    ret, frame = cap.read()\n",
    "    imgname = os.path.join(IMAGES_PATH,f'{str(uuid.uuid1())}.jpg')\n",
    "    cv2.imwrite(f'{imgname}', frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x): \n",
    "    byte_img = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in ['train','test','val']:\n",
    "    for file in os.listdir(os.path.join('data', folder, 'images')):\n",
    "        \n",
    "        filename = file.split('.')[0]+'.json'\n",
    "        existing_filepath = os.path.join('data','labels', filename)\n",
    "        if os.path.exists(existing_filepath): \n",
    "            new_filepath = os.path.join('data',folder,'labels',filename)\n",
    "            os.replace(existing_filepath, new_filepath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([alb.RandomCrop(width=450, height=450), \n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2), \n",
    "                         alb.RGBShift(p=0.2), \n",
    "                         alb.VerticalFlip(p=0.5)], \n",
    "                        keypoint_params=alb.KeypointParams(format='xy', label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose([\n",
       "  RandomCrop(always_apply=False, p=1.0, height=450, width=450),\n",
       "  HorizontalFlip(always_apply=False, p=0.5),\n",
       "  RandomBrightnessContrast(always_apply=False, p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True),\n",
       "  RandomGamma(always_apply=False, p=0.2, gamma_limit=(80, 120), eps=None),\n",
       "  RGBShift(always_apply=False, p=0.2, r_shift_limit=(-20, 20), g_shift_limit=(-20, 20), b_shift_limit=(-20, 20)),\n",
       "  VerticalFlip(always_apply=False, p=0.5),\n",
       "], p=1.0, bbox_params=None, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': True, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image must be numpy array type\n"
     ]
    }
   ],
   "source": [
    "for partition in ['train', 'test', 'val']: \n",
    "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
    "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
    "\n",
    "        classes = [0,0]\n",
    "        coords = [0,0,0.00001,0.00001]\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "    \n",
    "            if label['shapes'][0]['label']=='left_eye': \n",
    "                classes[0] = 1\n",
    "                coords[0] = np.squeeze(label['shapes'][0]['points'])[0]\n",
    "                coords[1] = np.squeeze(label['shapes'][0]['points'])[1]\n",
    "\n",
    "            if label['shapes'][1]['label']=='right_eye':\n",
    "                classes[1] = 1\n",
    "                coords[2] = np.squeeze(label['shapes'][1]['points'])[0]\n",
    "                coords[3] = np.squeeze(label['shapes'][1]['points'])[1]\n",
    "\n",
    "            # if len(label['shapes']) > 1:     \n",
    "            #     if label['shapes'][1]['label'] =='left_eye': \n",
    "            #         classes[0] = 1 \n",
    "            #         coords[0] = np.squeeze(label['shapes'][1]['points'])[0]\n",
    "            #         coords[1] = np.squeeze(label['shapes'][1]['points'])[1]\n",
    "\n",
    "            #     if label['shapes'][1]['label'] =='right_eye': \n",
    "            #         classes[1] = 1\n",
    "            #         coords[2] = np.squeeze(label['shapes'][1]['points'])[0]\n",
    "            #         coords[3] = np.squeeze(label['shapes'][1]['points'])[1]\n",
    "            \n",
    "            np.divide(coords, [640,480,640,480])\n",
    "                \n",
    "        try: \n",
    "            for x in range(60):\n",
    "                keypoints = [(coords[:2]), (coords[2:])]\n",
    "                augmented = augmentor(image=img, keypoints=keypoints, class_labels=['left_eye','right_eye'])\n",
    "                cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
    "\n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "                annotation['class'] = [0,0]\n",
    "                annotation['keypoints'] = [0,0,0,0]\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['keypoints']) > 0: \n",
    "                        for idx, cl in enumerate(augmented['class_labels']):\n",
    "                            if cl == 'left_eye': \n",
    "                                annotation['class'][0] = 1 \n",
    "                                annotation['keypoints'][0] = augmented['keypoints'][idx][0]\n",
    "                                annotation['keypoints'][1] = augmented['keypoints'][idx][1]\n",
    "                            if cl == 'right_eye': \n",
    "                                annotation['class'][1] = 1 \n",
    "                                annotation['keypoints'][2] = augmented['keypoints'][idx][0]\n",
    "                                annotation['keypoints'][3] = augmented['keypoints'][idx][1]\n",
    "                                \n",
    "                annotation['keypoints'] = list(np.divide(annotation['keypoints'], [450,450,450,450]))\n",
    "\n",
    "\n",
    "                with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
